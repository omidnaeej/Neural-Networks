{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_gaussian_quantiles\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate data for training & testing phase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "x, y = make_gaussian_quantiles(n_samples=300, n_features=8, n_classes=2, random_state=42)\n",
    "x = np.c_[np.ones(x.shape[0]), x]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defining `Relu` and `Sigmoid` as activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RELU(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def SIGMOID(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- class `ShallowNeuralNetwork`\n",
    "\n",
    "  - `__init__` : setting *learning rate*, *epoch numbers*, *threshold* and *wide* of each layer to *initializing weights*\n",
    "\n",
    "  - `learning_phase` : doing *forward pass* for predicting answer and doing *backward pass* to updating weights with Gradient Descent Backpropagation algorithm. \n",
    "  also reporting cost function every 10 epochs\n",
    "\n",
    "  - `testing_phase` : after ending learning phase, we use test data to testing the model by unseen data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShallowNeuralNetwork:\n",
    "    def __init__(self, epoch_num, \n",
    "                 learning_rate, \n",
    "                 threshold,\n",
    "                 input_layer_neuron_num, \n",
    "                 hidden_layer_neuron_num,\n",
    "                 output_layer_neuron_num):\n",
    "        \n",
    "        self.input_n = input_layer_neuron_num\n",
    "        self.hidden_n = hidden_layer_neuron_num\n",
    "        self.output_n = output_layer_neuron_num\n",
    "        self.epoch_num = epoch_num\n",
    "        self.learning_rate = learning_rate\n",
    "        self.w1 = np.random.randn(self.hidden_n, self.input_n)*.1\n",
    "        self.w2 = np.random.randn(self.output_n, self.hidden_n)*.1\n",
    "        self.teta = threshold\n",
    "    \n",
    "    def learning_phase(self):\n",
    "        for _ in range(self.epoch_num):\n",
    "            y_pred, a1 = self.forward_pass()      \n",
    "            self.backward_pass(y_pred, a1)\n",
    "            \n",
    "            y_pred = y_pred > self.teta\n",
    "            error = y_train-y_pred\n",
    "            cost = len(error[error!=0])\n",
    "            \n",
    "            if _%10==0: \n",
    "                print(f'epoch {_} - cost function = {cost/len(x_train)}')\n",
    "                \n",
    "                if cost == 0: return\n",
    "                            \n",
    "    def forward_pass(self):\n",
    "        z1 = np.dot(self.w1, np.transpose(x_train))\n",
    "        a1 = RELU(z1)\n",
    "            \n",
    "        z2 = np.dot(self.w2, a1)\n",
    "        y_pred = SIGMOID(z2)\n",
    "            \n",
    "        return y_pred, a1\n",
    "    \n",
    "    def backward_pass(self, y_pred, a1):\n",
    "        error = (-2/len(x_train))*(y_train-y_pred)\n",
    "        temp = 1-y_pred\n",
    "        delta_w2 = np.dot(np.multiply(np.multiply(error, y_pred), temp), \n",
    "                          np.transpose(a1))\n",
    "        \n",
    "        rounda1_z1 = a1>0\n",
    "        temp_w1 = np.transpose(np.dot(np.transpose(np.multiply(np.multiply(error, y_pred), temp)), \n",
    "                                      self.w2))\n",
    "        delta_w1 = np.dot(np.multiply(temp_w1, rounda1_z1), \n",
    "                          x_train)\n",
    "        \n",
    "        self.w1 -= self.learning_rate* delta_w1\n",
    "        self.w2 -= self.learning_rate* delta_w2\n",
    "    \n",
    "    def testing_phase(self):\n",
    "        z1 = np.dot(self.w1, np.transpose(x_test))\n",
    "        a1 = RELU(z1)\n",
    "                \n",
    "        z2 = np.dot(self.w2, a1)\n",
    "        y_pred = SIGMOID(z2)\n",
    "            \n",
    "        y_pred = y_pred >= self.teta\n",
    "        test_error = y_test - y_pred\n",
    "        \n",
    "        cost = len(test_error[test_error!=0])\n",
    "            \n",
    "        print(\"cost function for testing data = \", cost/len(x_test))\n",
    "                      \n",
    "    def check(self):\n",
    "        print(\"w1\", np.shape(self.w1))\n",
    "        print(\"x\", np.shape(x_train))\n",
    "        print(\"w2\", np.shape(self.w2))\n",
    "        print(\"y\", np.shape(y_train))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training model for different values of hyperparameters**\n",
    "1. training model (lr = .05, epoch number = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnmodel = ShallowNeuralNetwork(epoch_num=5000, \n",
    "                              learning_rate=.05, \n",
    "                              threshold=.5,\n",
    "                              input_layer_neuron_num=9, \n",
    "                              hidden_layer_neuron_num=1000, \n",
    "                              output_layer_neuron_num=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 - cost function = 0.5125\n",
      "epoch 10 - cost function = 0.5041666666666667\n",
      "epoch 20 - cost function = 0.44583333333333336\n",
      "epoch 30 - cost function = 0.42916666666666664\n",
      "epoch 40 - cost function = 0.3875\n",
      "epoch 50 - cost function = 0.35\n",
      "epoch 60 - cost function = 0.3458333333333333\n",
      "epoch 70 - cost function = 0.30416666666666664\n",
      "epoch 80 - cost function = 0.2791666666666667\n",
      "epoch 90 - cost function = 0.275\n",
      "epoch 100 - cost function = 0.25833333333333336\n",
      "epoch 110 - cost function = 0.25833333333333336\n",
      "epoch 120 - cost function = 0.23333333333333334\n",
      "epoch 130 - cost function = 0.23333333333333334\n",
      "epoch 140 - cost function = 0.2125\n",
      "epoch 150 - cost function = 0.2125\n",
      "epoch 160 - cost function = 0.20416666666666666\n",
      "epoch 170 - cost function = 0.17916666666666667\n",
      "epoch 180 - cost function = 0.16666666666666666\n",
      "epoch 190 - cost function = 0.1625\n",
      "epoch 200 - cost function = 0.15833333333333333\n",
      "epoch 210 - cost function = 0.15\n",
      "epoch 220 - cost function = 0.14583333333333334\n",
      "epoch 230 - cost function = 0.12083333333333333\n",
      "epoch 240 - cost function = 0.1125\n",
      "epoch 250 - cost function = 0.10416666666666667\n",
      "epoch 260 - cost function = 0.1\n",
      "epoch 270 - cost function = 0.09583333333333334\n",
      "epoch 280 - cost function = 0.0875\n",
      "epoch 290 - cost function = 0.08333333333333333\n",
      "epoch 300 - cost function = 0.08333333333333333\n",
      "epoch 310 - cost function = 0.08333333333333333\n",
      "epoch 320 - cost function = 0.075\n",
      "epoch 330 - cost function = 0.07083333333333333\n",
      "epoch 340 - cost function = 0.07083333333333333\n",
      "epoch 350 - cost function = 0.06666666666666667\n",
      "epoch 360 - cost function = 0.0625\n",
      "epoch 370 - cost function = 0.0625\n",
      "epoch 380 - cost function = 0.058333333333333334\n",
      "epoch 390 - cost function = 0.058333333333333334\n",
      "epoch 400 - cost function = 0.058333333333333334\n",
      "epoch 410 - cost function = 0.058333333333333334\n",
      "epoch 420 - cost function = 0.05416666666666667\n",
      "epoch 430 - cost function = 0.05\n",
      "epoch 440 - cost function = 0.05\n",
      "epoch 450 - cost function = 0.05\n",
      "epoch 460 - cost function = 0.05\n",
      "epoch 470 - cost function = 0.05\n",
      "epoch 480 - cost function = 0.041666666666666664\n",
      "epoch 490 - cost function = 0.041666666666666664\n",
      "epoch 500 - cost function = 0.041666666666666664\n",
      "epoch 510 - cost function = 0.041666666666666664\n",
      "epoch 520 - cost function = 0.041666666666666664\n",
      "epoch 530 - cost function = 0.0375\n",
      "epoch 540 - cost function = 0.0375\n",
      "epoch 550 - cost function = 0.0375\n",
      "epoch 560 - cost function = 0.0375\n",
      "epoch 570 - cost function = 0.0375\n",
      "epoch 580 - cost function = 0.0375\n",
      "epoch 590 - cost function = 0.0375\n",
      "epoch 600 - cost function = 0.0375\n",
      "epoch 610 - cost function = 0.0375\n",
      "epoch 620 - cost function = 0.0375\n",
      "epoch 630 - cost function = 0.03333333333333333\n",
      "epoch 640 - cost function = 0.03333333333333333\n",
      "epoch 650 - cost function = 0.03333333333333333\n",
      "epoch 660 - cost function = 0.03333333333333333\n",
      "epoch 670 - cost function = 0.029166666666666667\n",
      "epoch 680 - cost function = 0.029166666666666667\n",
      "epoch 690 - cost function = 0.029166666666666667\n",
      "epoch 700 - cost function = 0.029166666666666667\n",
      "epoch 710 - cost function = 0.025\n",
      "epoch 720 - cost function = 0.025\n",
      "epoch 730 - cost function = 0.025\n",
      "epoch 740 - cost function = 0.025\n",
      "epoch 750 - cost function = 0.025\n",
      "epoch 760 - cost function = 0.025\n",
      "epoch 770 - cost function = 0.025\n",
      "epoch 780 - cost function = 0.020833333333333332\n",
      "epoch 790 - cost function = 0.020833333333333332\n",
      "epoch 800 - cost function = 0.020833333333333332\n",
      "epoch 810 - cost function = 0.016666666666666666\n",
      "epoch 820 - cost function = 0.016666666666666666\n",
      "epoch 830 - cost function = 0.016666666666666666\n",
      "epoch 840 - cost function = 0.016666666666666666\n",
      "epoch 850 - cost function = 0.016666666666666666\n",
      "epoch 860 - cost function = 0.016666666666666666\n",
      "epoch 870 - cost function = 0.016666666666666666\n",
      "epoch 880 - cost function = 0.016666666666666666\n",
      "epoch 890 - cost function = 0.016666666666666666\n",
      "epoch 900 - cost function = 0.016666666666666666\n",
      "epoch 910 - cost function = 0.016666666666666666\n",
      "epoch 920 - cost function = 0.016666666666666666\n",
      "epoch 930 - cost function = 0.016666666666666666\n",
      "epoch 940 - cost function = 0.016666666666666666\n",
      "epoch 950 - cost function = 0.016666666666666666\n",
      "epoch 960 - cost function = 0.016666666666666666\n",
      "epoch 970 - cost function = 0.016666666666666666\n",
      "epoch 980 - cost function = 0.0125\n",
      "epoch 990 - cost function = 0.0125\n",
      "epoch 1000 - cost function = 0.0125\n",
      "epoch 1010 - cost function = 0.0125\n",
      "epoch 1020 - cost function = 0.0125\n",
      "epoch 1030 - cost function = 0.0125\n",
      "epoch 1040 - cost function = 0.0125\n",
      "epoch 1050 - cost function = 0.0125\n",
      "epoch 1060 - cost function = 0.0125\n",
      "epoch 1070 - cost function = 0.0125\n",
      "epoch 1080 - cost function = 0.0125\n",
      "epoch 1090 - cost function = 0.0125\n",
      "epoch 1100 - cost function = 0.0125\n",
      "epoch 1110 - cost function = 0.008333333333333333\n",
      "epoch 1120 - cost function = 0.008333333333333333\n",
      "epoch 1130 - cost function = 0.008333333333333333\n",
      "epoch 1140 - cost function = 0.008333333333333333\n",
      "epoch 1150 - cost function = 0.008333333333333333\n",
      "epoch 1160 - cost function = 0.008333333333333333\n",
      "epoch 1170 - cost function = 0.008333333333333333\n",
      "epoch 1180 - cost function = 0.008333333333333333\n",
      "epoch 1190 - cost function = 0.008333333333333333\n",
      "epoch 1200 - cost function = 0.008333333333333333\n",
      "epoch 1210 - cost function = 0.008333333333333333\n",
      "epoch 1220 - cost function = 0.008333333333333333\n",
      "epoch 1230 - cost function = 0.008333333333333333\n",
      "epoch 1240 - cost function = 0.008333333333333333\n",
      "epoch 1250 - cost function = 0.008333333333333333\n",
      "epoch 1260 - cost function = 0.008333333333333333\n",
      "epoch 1270 - cost function = 0.008333333333333333\n",
      "epoch 1280 - cost function = 0.008333333333333333\n",
      "epoch 1290 - cost function = 0.008333333333333333\n",
      "epoch 1300 - cost function = 0.008333333333333333\n",
      "epoch 1310 - cost function = 0.008333333333333333\n",
      "epoch 1320 - cost function = 0.008333333333333333\n",
      "epoch 1330 - cost function = 0.004166666666666667\n",
      "epoch 1340 - cost function = 0.004166666666666667\n",
      "epoch 1350 - cost function = 0.004166666666666667\n",
      "epoch 1360 - cost function = 0.004166666666666667\n",
      "epoch 1370 - cost function = 0.004166666666666667\n",
      "epoch 1380 - cost function = 0.004166666666666667\n",
      "epoch 1390 - cost function = 0.004166666666666667\n",
      "epoch 1400 - cost function = 0.004166666666666667\n",
      "epoch 1410 - cost function = 0.004166666666666667\n",
      "epoch 1420 - cost function = 0.004166666666666667\n",
      "epoch 1430 - cost function = 0.004166666666666667\n",
      "epoch 1440 - cost function = 0.004166666666666667\n",
      "epoch 1450 - cost function = 0.004166666666666667\n",
      "epoch 1460 - cost function = 0.004166666666666667\n",
      "epoch 1470 - cost function = 0.004166666666666667\n",
      "epoch 1480 - cost function = 0.004166666666666667\n",
      "epoch 1490 - cost function = 0.004166666666666667\n",
      "epoch 1500 - cost function = 0.004166666666666667\n",
      "epoch 1510 - cost function = 0.004166666666666667\n",
      "epoch 1520 - cost function = 0.004166666666666667\n",
      "epoch 1530 - cost function = 0.004166666666666667\n",
      "epoch 1540 - cost function = 0.004166666666666667\n",
      "epoch 1550 - cost function = 0.004166666666666667\n",
      "epoch 1560 - cost function = 0.004166666666666667\n",
      "epoch 1570 - cost function = 0.004166666666666667\n",
      "epoch 1580 - cost function = 0.004166666666666667\n",
      "epoch 1590 - cost function = 0.004166666666666667\n",
      "epoch 1600 - cost function = 0.004166666666666667\n",
      "epoch 1610 - cost function = 0.004166666666666667\n",
      "epoch 1620 - cost function = 0.004166666666666667\n",
      "epoch 1630 - cost function = 0.004166666666666667\n",
      "epoch 1640 - cost function = 0.004166666666666667\n",
      "epoch 1650 - cost function = 0.004166666666666667\n",
      "epoch 1660 - cost function = 0.004166666666666667\n",
      "epoch 1670 - cost function = 0.004166666666666667\n",
      "epoch 1680 - cost function = 0.004166666666666667\n",
      "epoch 1690 - cost function = 0.004166666666666667\n",
      "epoch 1700 - cost function = 0.004166666666666667\n",
      "epoch 1710 - cost function = 0.004166666666666667\n",
      "epoch 1720 - cost function = 0.004166666666666667\n",
      "epoch 1730 - cost function = 0.004166666666666667\n",
      "epoch 1740 - cost function = 0.004166666666666667\n",
      "epoch 1750 - cost function = 0.0\n"
     ]
    }
   ],
   "source": [
    "nnmodel.learning_phase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost function for testing data =  0.03333333333333333\n"
     ]
    }
   ],
   "source": [
    "nnmodel.testing_phase()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. training model (lr = .25, epoch number = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 - cost function = 0.4375\n",
      "epoch 10 - cost function = 0.2833333333333333\n",
      "epoch 20 - cost function = 0.2\n",
      "epoch 30 - cost function = 0.1875\n",
      "epoch 40 - cost function = 0.15416666666666667\n",
      "epoch 50 - cost function = 0.11666666666666667\n",
      "epoch 60 - cost function = 0.10833333333333334\n",
      "epoch 70 - cost function = 0.09166666666666666\n",
      "epoch 80 - cost function = 0.08333333333333333\n",
      "epoch 90 - cost function = 0.0625\n",
      "epoch 100 - cost function = 0.05\n",
      "epoch 110 - cost function = 0.04583333333333333\n",
      "epoch 120 - cost function = 0.04583333333333333\n",
      "epoch 130 - cost function = 0.04583333333333333\n",
      "epoch 140 - cost function = 0.0375\n",
      "epoch 150 - cost function = 0.03333333333333333\n",
      "epoch 160 - cost function = 0.025\n",
      "epoch 170 - cost function = 0.025\n",
      "epoch 180 - cost function = 0.020833333333333332\n",
      "epoch 190 - cost function = 0.016666666666666666\n",
      "epoch 200 - cost function = 0.0125\n",
      "epoch 210 - cost function = 0.0125\n",
      "epoch 220 - cost function = 0.008333333333333333\n",
      "epoch 230 - cost function = 0.008333333333333333\n",
      "epoch 240 - cost function = 0.008333333333333333\n",
      "epoch 250 - cost function = 0.008333333333333333\n",
      "epoch 260 - cost function = 0.008333333333333333\n",
      "epoch 270 - cost function = 0.008333333333333333\n",
      "epoch 280 - cost function = 0.004166666666666667\n",
      "epoch 290 - cost function = 0.004166666666666667\n",
      "epoch 300 - cost function = 0.004166666666666667\n",
      "epoch 310 - cost function = 0.004166666666666667\n",
      "epoch 320 - cost function = 0.004166666666666667\n",
      "epoch 330 - cost function = 0.004166666666666667\n",
      "epoch 340 - cost function = 0.004166666666666667\n",
      "epoch 350 - cost function = 0.0\n"
     ]
    }
   ],
   "source": [
    "nnmodel2 = ShallowNeuralNetwork(epoch_num=5000, \n",
    "                              learning_rate=.25, \n",
    "                              threshold=.5,\n",
    "                              input_layer_neuron_num=9, \n",
    "                              hidden_layer_neuron_num=1000, \n",
    "                              output_layer_neuron_num=1)\n",
    "nnmodel2.learning_phase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost function for testing data =  0.03333333333333333\n"
     ]
    }
   ],
   "source": [
    "nnmodel2.testing_phase()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. training model (lr = .5, epoch number = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 - cost function = 0.5\n",
      "epoch 10 - cost function = 0.275\n",
      "epoch 20 - cost function = 0.15416666666666667\n",
      "epoch 30 - cost function = 0.11666666666666667\n",
      "epoch 40 - cost function = 0.08333333333333333\n",
      "epoch 50 - cost function = 0.0625\n",
      "epoch 60 - cost function = 0.041666666666666664\n",
      "epoch 70 - cost function = 0.03333333333333333\n",
      "epoch 80 - cost function = 0.03333333333333333\n",
      "epoch 90 - cost function = 0.025\n",
      "epoch 100 - cost function = 0.016666666666666666\n",
      "epoch 110 - cost function = 0.016666666666666666\n",
      "epoch 120 - cost function = 0.008333333333333333\n",
      "epoch 130 - cost function = 0.004166666666666667\n",
      "epoch 140 - cost function = 0.004166666666666667\n",
      "epoch 150 - cost function = 0.004166666666666667\n",
      "epoch 160 - cost function = 0.0\n"
     ]
    }
   ],
   "source": [
    "nnmodel3 = ShallowNeuralNetwork(epoch_num=5000, \n",
    "                              learning_rate=.5, \n",
    "                              threshold=.5,\n",
    "                              input_layer_neuron_num=9, \n",
    "                              hidden_layer_neuron_num=1000, \n",
    "                              output_layer_neuron_num=1)\n",
    "nnmodel3.learning_phase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost function for testing data =  0.016666666666666666\n"
     ]
    }
   ],
   "source": [
    "nnmodel3.testing_phase()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. training model (lr = .75, epoch number = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 - cost function = 0.5083333333333333\n",
      "epoch 10 - cost function = 0.18333333333333332\n",
      "epoch 20 - cost function = 0.15833333333333333\n",
      "epoch 30 - cost function = 0.09583333333333334\n",
      "epoch 40 - cost function = 0.05\n",
      "epoch 50 - cost function = 0.03333333333333333\n",
      "epoch 60 - cost function = 0.020833333333333332\n",
      "epoch 70 - cost function = 0.016666666666666666\n",
      "epoch 80 - cost function = 0.008333333333333333\n",
      "epoch 90 - cost function = 0.008333333333333333\n",
      "epoch 100 - cost function = 0.004166666666666667\n",
      "epoch 110 - cost function = 0.0\n"
     ]
    }
   ],
   "source": [
    "nnmodel4 = ShallowNeuralNetwork(epoch_num=5000, \n",
    "                              learning_rate=.75, \n",
    "                              threshold=.5,\n",
    "                              input_layer_neuron_num=9, \n",
    "                              hidden_layer_neuron_num=1000, \n",
    "                              output_layer_neuron_num=1)\n",
    "nnmodel4.learning_phase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost function for testing data =  0.06666666666666667\n"
     ]
    }
   ],
   "source": [
    "nnmodel4.testing_phase()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. training model (lr = .99, epoch number = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 - cost function = 0.5\n",
      "epoch 10 - cost function = 0.2791666666666667\n",
      "epoch 20 - cost function = 0.225\n",
      "epoch 30 - cost function = 0.175\n",
      "epoch 40 - cost function = 0.13333333333333333\n",
      "epoch 50 - cost function = 0.0875\n",
      "epoch 60 - cost function = 0.04583333333333333\n",
      "epoch 70 - cost function = 0.025\n",
      "epoch 80 - cost function = 0.004166666666666667\n",
      "epoch 90 - cost function = 0.004166666666666667\n",
      "epoch 100 - cost function = 0.004166666666666667\n",
      "epoch 110 - cost function = 0.0\n"
     ]
    }
   ],
   "source": [
    "nnmodel5 = ShallowNeuralNetwork(epoch_num=5000, \n",
    "                              learning_rate=.99, \n",
    "                              threshold=.5,\n",
    "                              input_layer_neuron_num=9, \n",
    "                              hidden_layer_neuron_num=1000, \n",
    "                              output_layer_neuron_num=1)\n",
    "nnmodel5.learning_phase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost function for testing data =  0.03333333333333333\n"
     ]
    }
   ],
   "source": [
    "nnmodel5.testing_phase()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>epochs</td>\n",
    "        <td>learning rate</td>\n",
    "        <td>loss validation</td>\n",
    "        <td>loss</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>1750</td>\n",
    "        <td>0.05</td>\n",
    "        <td>0.0333</td>\n",
    "        <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>350</td>\n",
    "        <td>0.25</td>\n",
    "        <td>0.0333</td>\n",
    "        <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>160</td>\n",
    "        <td>0.50</td>\n",
    "        <td>0.0167</td>\n",
    "        <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>110</td>\n",
    "        <td>0.75</td>\n",
    "        <td>0.0667</td>\n",
    "        <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>110</td>\n",
    "        <td>0.99</td>\n",
    "        <td>0.0333</td>\n",
    "        <td>0</td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "because learning was truncated when loss equals zero, increasing epochs won't have any effect but decreasing it could increase loss validation.\n",
    "\n",
    "So the best model is number 3, because it has the lowest loss validation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
